{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cindyweng18/csc448_hw/blob/main/Assignment4.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "    species  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris = load_iris()\n",
    "features = iris['feature_names']\n",
    "target = 'species' \n",
    "\n",
    "df = pd.DataFrame(iris['data'], columns=features)\n",
    "df[target] = iris['target']\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)     species  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "\n",
    "There are a total of 150 entries for this dataset and the measured numbers for each column (cm) seem to be reasonable and within \"normal\" range, that is, there isn't a maximum of 20 cm or a minimum of 0 cm. When we print out the `iris` dataset imported from `Sklearn`, we can see that it has the features and labels that we need. The features are `sepal length (cm)`, `sepal width (cm)`, `petal length (cm)`, `petal width (cm)`. And the label is the species that the flower corresponds to which is an integer instead of the string value of the flower species since the target array from the iris dataset is composed of 0, 1, 2. This mapping of labels corresponds to the actual classes: `setosa`, `versicolor`, `virginica` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X = df[features]\n",
    "Y = df[target]\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities [Class 0, Class 1, Class 2]:  [1.29486547e-04 7.88544378e-04 9.99081969e-01]\n",
      "Score:  1.0\n",
      "Coefficients:  [[-0.40407204  0.92665844 -2.45635453 -1.06431032]\n",
      " [ 0.53710156 -0.33020752 -0.20143971 -0.88843883]\n",
      " [-0.13302952 -0.59645093  2.65779424  1.95274915]]\n",
      "Y-Intercept:  [  9.60566957   2.10586786 -11.71153744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample = np.array([[4.4, 4.4, 4.4, 4.4]])\n",
    "print(\"Predicted Probabilities [Class 0, Class 1, Class 2]: \", reg.predict_proba(sample)[0])\n",
    "\n",
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "print(\"Score: \", reg_score)\n",
    "\n",
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "coef = reg.coef_\n",
    "y_int = reg.intercept_\n",
    "print(\"Coefficients: \", coef)\n",
    "print(\"Y-Intercept: \", y_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the logistic regression moddel is 1.0, this score measure the mean accuracy of the testing dataset where accuracy is defined as the number of correct predictions made divided by the total number of datapoints in the subset. A score of 1.0 means that the model was able to correctly predict all the datapoints in the testing set with respect to the predicted values obtained from the features testing set and comparing it with the target testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities [Class 0, Class 1, Class 2]: [0.07346016 0.03168489 0.89485494]\n",
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svc = SVC(probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample = np.array([[4.4, 4.4, 4.4, 4.4]])\n",
    "print(\"Predicted Probabilities [Class 0, Class 1, Class 2]:\", svc.predict_proba(sample)[0])\n",
    "\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "svc_score = svc.score(X_test, y_test)\n",
    "print(\"Score: \", svc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the SVM is 1.0, this score measure the mean accuracy of the testing dataset where accuracy is defined as the number of correct predictions made divided by the total number of datapoints in the subset. A score of 1.0 means that the model was able to correctly predict all the datapoints in the testing set with respect to the predicted values obtained from the features testing set and comparing it with the target testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities [Class 0, Class 1, Class 2]: [7.00672418e-04 3.14370456e-03 9.96155623e-01]\n",
      "Score:  1.0\n",
      "Score of modified neural network:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample = np.array([[4.4, 4.4, 4.4, 4.4]])\n",
    "print(\"Predicted Probabilities [Class 0, Class 1, Class 2]:\", mlp.predict_proba(sample)[0])\n",
    "\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "mlp_score = mlp.score(X_test, y_test)\n",
    "print(\"Score: \", mlp_score)\n",
    "\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "diff_mlp = MLPClassifier(\n",
    "            activation='logistic',\n",
    "            solver='lbfgs',\n",
    "            alpha=0.1,\n",
    "            tol=0.001\n",
    ")\n",
    "diff_mlp.fit(X_train, y_train)\n",
    "diff_score = diff_mlp.score(X_test, y_test)\n",
    "print(\"Score of modified neural network: \", diff_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the neural network is 1.0, this score measure the mean accuracy of the testing dataset where accuracy is defined as the number of correct predictions made divided by the total number of datapoints in the subset. A score of 1.0 means that the model was able to correctly predict all the datapoints in the testing set with respect to the predicted values obtained from the features testing set and comparing it with the target testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities [Class 0, Class 1, Class 2]: [0.  0.2 0.8]\n",
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Predicted Probabilities [Class 0, Class 1, Class 2]:\", knn.predict_proba(sample)[0])\n",
    "\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(\"Score: \", knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the kNN is 1.0, this score measure the mean accuracy of the testing dataset where accuracy is defined as the number of correct predictions made divided by the total number of datapoints in the subset. A score of 1.0 means that the model was able to correctly predict all the datapoints in the testing set with respect to the predicted values obtained from the features testing set and comparing it with the target testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the notebook were the same througout all the models. The models scored a 100% accuracy so all the models performed best on the dataset. I think this is because this is a small dataset (total of 150 items) and there are very few features that we can use when training a model compared to more realistic datasets where you can have 100,000 items and so many features to choose from when training a model. One thing that surprised me about the exercise was how great the models scored which almost seem like it was too good to be true."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
